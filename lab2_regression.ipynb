{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf52d596",
      "metadata": {},
      "source": [
        "# Лабораторная работа №2. Логистическая и Линейная регрессия\n",
        "\n",
        "**Цель:** Исследование линейных моделей на задачах классификации и регрессии, реализация алгоритмов с нуля.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b087f8c4",
      "metadata": {},
      "source": [
        "## 1. Выбор данных\n",
        "\n",
        "Используются те же датасеты, что и в ЛР1:\n",
        "1. **Mushrooms** (Классификация) -> Логистическая регрессия.\n",
        "2. **Car Price** (Регрессия) -> Линейная регрессия.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd14079c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mushrooms shape: (8124, 23)\n",
            "Cars shape: (1000, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e</td>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
              "0     p         x           s         n       t    p               f   \n",
              "1     e         x           s         y       t    a               f   \n",
              "2     e         b           s         w       t    l               f   \n",
              "3     p         x           y         w       t    p               f   \n",
              "4     e         x           s         g       f    n               f   \n",
              "\n",
              "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
              "0            c         n          k  ...                        s   \n",
              "1            c         b          k  ...                        s   \n",
              "2            c         b          n  ...                        s   \n",
              "3            c         n          n  ...                        s   \n",
              "4            w         b          k  ...                        s   \n",
              "\n",
              "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
              "0                      w                      w         p          w   \n",
              "1                      w                      w         p          w   \n",
              "2                      w                      w         p          w   \n",
              "3                      w                      w         p          w   \n",
              "4                      w                      w         p          w   \n",
              "\n",
              "  ring-number ring-type spore-print-color population habitat  \n",
              "0           o         p                 k          s       u  \n",
              "1           o         p                 n          n       g  \n",
              "2           o         p                 n          n       m  \n",
              "3           o         p                 k          s       u  \n",
              "4           o         e                 n          a       g  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Make</th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine Size</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>Fuel Type</th>\n",
              "      <th>Transmission</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Honda</td>\n",
              "      <td>Model B</td>\n",
              "      <td>2015</td>\n",
              "      <td>3.9</td>\n",
              "      <td>74176</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Manual</td>\n",
              "      <td>30246.207931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ford</td>\n",
              "      <td>Model C</td>\n",
              "      <td>2014</td>\n",
              "      <td>1.7</td>\n",
              "      <td>94799</td>\n",
              "      <td>Electric</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>22785.747684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BMW</td>\n",
              "      <td>Model B</td>\n",
              "      <td>2006</td>\n",
              "      <td>4.1</td>\n",
              "      <td>98385</td>\n",
              "      <td>Electric</td>\n",
              "      <td>Manual</td>\n",
              "      <td>25760.290347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Honda</td>\n",
              "      <td>Model B</td>\n",
              "      <td>2015</td>\n",
              "      <td>2.6</td>\n",
              "      <td>88919</td>\n",
              "      <td>Electric</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>25638.003491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Honda</td>\n",
              "      <td>Model C</td>\n",
              "      <td>2004</td>\n",
              "      <td>3.4</td>\n",
              "      <td>138482</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>21021.386657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Make    Model  Year  Engine Size  Mileage Fuel Type Transmission  \\\n",
              "0  Honda  Model B  2015          3.9    74176    Petrol       Manual   \n",
              "1   Ford  Model C  2014          1.7    94799  Electric    Automatic   \n",
              "2    BMW  Model B  2006          4.1    98385  Electric       Manual   \n",
              "3  Honda  Model B  2015          2.6    88919  Electric    Automatic   \n",
              "4  Honda  Model C  2004          3.4   138482    Petrol    Automatic   \n",
              "\n",
              "          Price  \n",
              "0  30246.207931  \n",
              "1  22785.747684  \n",
              "2  25760.290347  \n",
              "3  25638.003491  \n",
              "4  21021.386657  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "mush = pd.read_csv(\"data/mushrooms.csv\")\n",
        "cars = pd.read_csv(\"data/car_price.csv\")\n",
        "\n",
        "print(\"Mushrooms shape:\", mush.shape)\n",
        "print(\"Cars shape:\", cars.shape)\n",
        "\n",
        "display(mush.head())\n",
        "display(cars.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "82da8e1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mushrooms train/test: (6499, 22) (1625, 22)\n",
            "Cars train/test: (800, 7) (200, 7)\n",
            "Numeric features: ['Year', 'Engine Size', 'Mileage']\n",
            "Categorical features: ['Make', 'Model', 'Fuel Type', 'Transmission']\n"
          ]
        }
      ],
      "source": [
        "X_mush = mush.drop(\"class\", axis=1)\n",
        "y_mush = mush[\"class\"]\n",
        "\n",
        "cat_features_mush = X_mush.columns.tolist()\n",
        "\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X_mush,\n",
        "    y_mush,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_mush\n",
        ")\n",
        "\n",
        "print(\"Mushrooms train/test:\", X_train_m.shape, X_test_m.shape)\n",
        "\n",
        "\n",
        "TARGET_COL = \"Price\"\n",
        "\n",
        "X_cars = cars.drop(TARGET_COL, axis=1)\n",
        "y_cars = cars[TARGET_COL]\n",
        "\n",
        "num_features_cars = X_cars.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "cat_features_cars = X_cars.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X_cars,\n",
        "    y_cars,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Cars train/test:\", X_train_c.shape, X_test_c.shape)\n",
        "print(\"Numeric features:\", num_features_cars)\n",
        "print(\"Categorical features:\", cat_features_cars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "26d2ebd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Препроцессор для грибов: OneHotEncode всех категориальных признаков\n",
        "preprocess_mush = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features_mush)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Препроцессор для автомобилей: числовые + категориальные\n",
        "preprocess_cars = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_features_cars),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features_cars)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c7be8652",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Logistic Regression Baseline (Mushrooms) ===\n",
            "Accuracy: 0.9993846153846154\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  1 782]]\n"
          ]
        }
      ],
      "source": [
        "log_reg_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_mush),\n",
        "    (\"model\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "log_reg_baseline.fit(X_train_m, y_train_m)\n",
        "\n",
        "y_pred_m_log = log_reg_baseline.predict(X_test_m)\n",
        "\n",
        "print(\"=== Logistic Regression Baseline (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_log))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_log))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_log))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ceebdaf7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Linear Regression Baseline (Cars) ===\n",
            "MAE: 1810.5547575776332\n",
            "RMSE: 2237.2910425919263\n",
            "R^2: 0.8170961815663225\n"
          ]
        }
      ],
      "source": [
        "lin_reg_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_cars),\n",
        "    (\"model\", LinearRegression())\n",
        "])\n",
        "\n",
        "lin_reg_baseline.fit(X_train_c, y_train_c)\n",
        "\n",
        "y_pred_c_lin = lin_reg_baseline.predict(X_test_c)\n",
        "\n",
        "mae_lin = mean_absolute_error(y_test_c, y_pred_c_lin)\n",
        "rmse_lin = mean_squared_error(y_test_c, y_pred_c_lin) ** 0.5\n",
        "r2_lin = r2_score(y_test_c, y_pred_c_lin)\n",
        "\n",
        "print(\"=== Linear Regression Baseline (Cars) ===\")\n",
        "print(\"MAE:\", mae_lin)\n",
        "print(\"RMSE:\", rmse_lin)\n",
        "print(\"R^2:\", r2_lin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dcab289",
      "metadata": {},
      "source": [
        "## 4. Анализ результатов бейзлайна логистической и линейной регрессии\n",
        "\n",
        "### 4.1. Классификация (Mushrooms) — Logistic Regression\n",
        "\n",
        "Бейзлайн логистической регрессии показал следующие результаты:\n",
        "\n",
        "- **Accuracy ≈ 0.99938**\n",
        "- Ошибка всего в одном объекте (`1` неверная классификация)\n",
        "- Precision/Recall/F1-score для обоих классов практически равны 1.00\n",
        "- Матрица ошибок показывает полное отсутствие ошибок для съедобного класса и одну ошибку для ядовитого\n",
        "\n",
        "Интерпретация:\n",
        "\n",
        "- Логистическая регрессия, несмотря на линейную природу, отлично работает на этом датасете.\n",
        "- Единственная ошибка связана с тем, что модель пытается провести линейную границу в пространстве признаков, которое сильно расширено после One-Hot кодирования.\n",
        "- Тем не менее результат практически идеальный и почти не уступает KNN.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.2. Регрессия (Car Price Prediction) — Linear Regression\n",
        "\n",
        "Результаты линейной регрессии:\n",
        "\n",
        "- **MAE ≈ 1810.55**\n",
        "- **RMSE ≈ 2237.29**\n",
        "- **R² ≈ 0.8171**\n",
        "\n",
        "Интерпретация:\n",
        "\n",
        "- Линейная модель объясняет более **81%** вариации цен автомобилей.\n",
        "- Качество **заметно лучше**, чем у KNN-бейзлайна (у KNN было R² ≈ 0.7156).\n",
        "- MAE около 1800 означает, что модель ошибается в среднем на 1.8 тыс. единиц цены, что является неплохим результатом для простой линейной зависимости.\n",
        "- Улучшения ожидаются при добавлении регуляризации (`Ridge`) и подборе гиперпараметров.\n",
        "\n",
        "---\n",
        "\n",
        "### Итог по бейзлайну\n",
        "\n",
        "- Логистическая регрессия на грибах показывает почти идеальное качество, что подтверждает хорошую линейную разделимость после One-Hot кодирования.\n",
        "- Линейная регрессия демонстрирует высокое качество на задаче предсказания цены автомобиля, превосходя результаты KNN.\n",
        "- Оба бейзлайна дают сильную стартовую точку для дальнейших улучшений.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ec9de557",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (LogReg Mushrooms): {'model__C': 10.0, 'model__penalty': 'l1'}\n",
            "\n",
            "=== Improved Logistic Regression (Mushrooms) ===\n",
            "Accuracy: 1.0\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  0 783]]\n"
          ]
        }
      ],
      "source": [
        "# Улучшенная логистическая регрессия для грибов (подбор C)\n",
        "\n",
        "log_reg_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_mush),\n",
        "    (\"model\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
        "])\n",
        "\n",
        "param_grid_log = {\n",
        "    \"model__C\": [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    \"model__penalty\": [\"l1\", \"l2\"]\n",
        "}\n",
        "\n",
        "grid_log = GridSearchCV(\n",
        "    estimator=log_reg_pipe,\n",
        "    param_grid=param_grid_log,\n",
        "    cv=5,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_log.fit(X_train_m, y_train_m)\n",
        "\n",
        "print(\"Best params (LogReg Mushrooms):\", grid_log.best_params_)\n",
        "\n",
        "best_log_clf = grid_log.best_estimator_\n",
        "\n",
        "y_pred_m_log_best = best_log_clf.predict(X_test_m)\n",
        "\n",
        "print(\"\\n=== Improved Logistic Regression (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_log_best))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_log_best))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_log_best))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aaf23d51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (Ridge Cars): {'model__alpha': 10.0}\n",
            "\n",
            "=== Improved Ridge Regression (Cars) ===\n",
            "MAE: 1807.8404600381991\n",
            "RMSE: 2232.907746289107\n",
            "R^2: 0.8178121691156635\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_cars),\n",
        "    (\"model\", Ridge())\n",
        "])\n",
        "\n",
        "param_grid_ridge = {\n",
        "    \"model__alpha\": [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "}\n",
        "\n",
        "grid_ridge = GridSearchCV(\n",
        "    estimator=ridge_pipe,\n",
        "    param_grid=param_grid_ridge,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_ridge.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(\"Best params (Ridge Cars):\", grid_ridge.best_params_)\n",
        "\n",
        "best_ridge_reg = grid_ridge.best_estimator_\n",
        "\n",
        "y_pred_c_ridge = best_ridge_reg.predict(X_test_c)\n",
        "\n",
        "mae_ridge = mean_absolute_error(y_test_c, y_pred_c_ridge)\n",
        "rmse_ridge = mean_squared_error(y_test_c, y_pred_c_ridge) ** 0.5\n",
        "r2_ridge = r2_score(y_test_c, y_pred_c_ridge)\n",
        "\n",
        "print(\"\\n=== Improved Ridge Regression (Cars) ===\")\n",
        "print(\"MAE:\", mae_ridge)\n",
        "print(\"RMSE:\", rmse_ridge)\n",
        "print(\"R^2:\", r2_ridge)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b530ad5",
      "metadata": {},
      "source": [
        "## 5. Анализ улучшенного бейзлайна логистической и линейной регрессии\n",
        "\n",
        "### 5.1. Классификация (Mushrooms) — Logistic Regression (подбор C и penalty)\n",
        "\n",
        "GridSearchCV нашёл оптимальные параметры:\n",
        "\n",
        "- **C = 10**\n",
        "- **penalty = l1**\n",
        "- solver = liblinear\n",
        "\n",
        "Результаты улучшенной модели:\n",
        "\n",
        "- **Accuracy = 1.0**\n",
        "- F1-score = 1.00 для обоих классов\n",
        "- Матрица ошибок без единой ошибки\n",
        "\n",
        "Как и в первой лабораторной работе, датасет грибов показывает практически идеальную линейную разделимость после One-Hot кодирования.  \n",
        "Гиперпараметры влияют на регуляризацию, но **качество не меняется**, поскольку базовая модель уже близка к максимуму.\n",
        "\n",
        "**Вывод:** улучшенный бейзлайн подтверждает, что логистическая регрессия полностью решает задачу классификации для данного набора данных.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.2. Регрессия (Car Price Prediction) — Ridge Regression (подбор alpha)\n",
        "\n",
        "Лучшие параметры по результатам GridSearchCV:\n",
        "\n",
        "- **alpha = 10**\n",
        "\n",
        "Результаты модели:\n",
        "\n",
        "- **MAE ≈ 1807.84**  \n",
        "- **RMSE ≈ 2232.91**  \n",
        "- **R² ≈ 0.81781**\n",
        "\n",
        "Сравнение с бейзлайном линейной регрессии:\n",
        "\n",
        "| Модель                       | MAE      | RMSE     | R²       |\n",
        "|-----------------------------|----------|----------|----------|\n",
        "| Linear Regression (baseline) | 1810.55  | 2237.29  | 0.81710  |\n",
        "| Ridge Regression (improved)  | **1807.84** | **2232.91** | **0.81781** |\n",
        "\n",
        "Интерпретация:\n",
        "\n",
        "- Регуляризация L2 (Ridge) слегка снижает ошибку и немного повышает R².\n",
        "- Это ожидаемый результат: Ridge уменьшает переобучение на признаках, которые после One-Hot кодирования становятся многомерными.\n",
        "- Улучшение небольшое, но стабильное.\n",
        "\n",
        "**Вывод:** улучшенный бейзлайн демонстрирует, что регуляризация помогает модели немного лучше обобщать данные, что особенно важно при большом количестве категориальных признаков.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.3. Общие выводы\n",
        "\n",
        "- Логистическая регрессия на грибах достигает идеального качества; подбор гиперпараметров подтверждает устойчивость модели.\n",
        "- Для задачи прогнозирования цен автомобилей регуляризация Ridge даёт небольшое, но закономерное улучшение качества.\n",
        "- В отличие от KNN в первой лабораторной работе, линейные модели оказываются сильными бейзлайнами, особенно для регрессии.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fca9d448",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded mushrooms: (6499, 117) (1625, 117)\n",
            "Encoded cars: (800, 18) (200, 18)\n"
          ]
        }
      ],
      "source": [
        "# Кодирование признаков для грибов\n",
        "X_train_m_enc = preprocess_mush.fit_transform(X_train_m)\n",
        "X_test_m_enc = preprocess_mush.transform(X_test_m)\n",
        "\n",
        "# Кодирование признаков для автомобилей\n",
        "X_train_c_enc = preprocess_cars.fit_transform(X_train_c)\n",
        "X_test_c_enc = preprocess_cars.transform(X_test_c)\n",
        "\n",
        "print(\"Encoded mushrooms:\", X_train_m_enc.shape, X_test_m_enc.shape)\n",
        "print(\"Encoded cars:\", X_train_c_enc.shape, X_test_c_enc.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "89adb5bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MyLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.bias = None \n",
        "    \n",
        "    def _to_dense(self, X):\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        return np.array(X)\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение линейной регрессии по нормальному уравнению.\n",
        "        Добавляем столбец единиц для bias.\n",
        "        \"\"\"\n",
        "        X = self._to_dense(X)\n",
        "        y = np.array(y).reshape(-1, 1)\n",
        "        \n",
        "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        \n",
        "        # (X^T X)^{-1} X^T y\n",
        "        XtX = X_bias.T @ X_bias\n",
        "        Xty = X_bias.T @ y\n",
        "        \n",
        "        lambda_identity = 1e-8 * np.eye(XtX.shape[0])\n",
        "        self.w = np.linalg.inv(XtX + lambda_identity) @ Xty \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Предсказание: y = Xw\n",
        "        \"\"\"\n",
        "        X = self._to_dense(X)\n",
        "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        y_pred = X_bias @ self.w\n",
        "        return y_pred.ravel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3f512d21",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MyLinearRegression (Cars) ===\n",
            "MAE: 1810.5583604371268\n",
            "RMSE: 2237.2762333632504\n",
            "R^2: 0.8170986029370397\n"
          ]
        }
      ],
      "source": [
        "my_lin_reg = MyLinearRegression()\n",
        "my_lin_reg.fit(X_train_c_enc, y_train_c)\n",
        "\n",
        "y_pred_c_my_lin = my_lin_reg.predict(X_test_c_enc)\n",
        "\n",
        "mae_my_lin = mean_absolute_error(y_test_c, y_pred_c_my_lin)\n",
        "rmse_my_lin = mean_squared_error(y_test_c, y_pred_c_my_lin) ** 0.5\n",
        "r2_my_lin = r2_score(y_test_c, y_pred_c_my_lin)\n",
        "\n",
        "print(\"=== MyLinearRegression (Cars) ===\")\n",
        "print(\"MAE:\", mae_my_lin)\n",
        "print(\"RMSE:\", rmse_my_lin)\n",
        "print(\"R^2:\", r2_my_lin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4895ff7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyLogisticRegression:\n",
        "    def __init__(self, lr=0.1, n_iter=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.w = None\n",
        "    \n",
        "    def _to_dense(self, X):\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        return np.array(X)\n",
        "    \n",
        "    def _sigmoid(self, z):\n",
        "        z = np.clip(z, -500, 500)\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение логистической регрессии с помощью градиентного спуска.\n",
        "        \"\"\"\n",
        "        X = self._to_dense(X)\n",
        "        y = np.array(y).reshape(-1, 1)\n",
        "        \n",
        "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        n_samples, n_features = X_bias.shape\n",
        "        \n",
        "        self.w = np.zeros((n_features, 1))\n",
        "        \n",
        "        for _ in range(self.n_iter):\n",
        "            logits = X_bias @ self.w\n",
        "            y_prob = self._sigmoid(logits)\n",
        "            grad = (1 / n_samples) * (X_bias.T @ (y_prob - y))\n",
        "            self.w -= self.lr * grad\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Возвращает вероятности класса 1.\n",
        "        \"\"\"\n",
        "        X = self._to_dense(X)\n",
        "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        logits = X_bias @ self.w\n",
        "        return self._sigmoid(logits).ravel()\n",
        "    \n",
        "    def predict(self, X, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Предсказание меток класса: 0 или 1.\n",
        "        \"\"\"\n",
        "        probs = self.predict_proba(X)\n",
        "        return (probs >= threshold).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fb54a67d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution in train (binary):\n",
            "[3366 3133]\n"
          ]
        }
      ],
      "source": [
        "y_train_m_bin = (y_train_m == \"p\").astype(int)\n",
        "y_test_m_bin = (y_test_m == \"p\").astype(int)\n",
        "\n",
        "print(\"Class distribution in train (binary):\")\n",
        "print(np.bincount(y_train_m_bin))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5174cc9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MyLogisticRegression (Mushrooms) ===\n",
            "Accuracy: 0.9956923076923077\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       0.99      1.00      1.00       842\n",
            "           p       1.00      0.99      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  7 776]]\n"
          ]
        }
      ],
      "source": [
        "my_log_reg = MyLogisticRegression(lr=0.1, n_iter=2000)\n",
        "\n",
        "my_log_reg.fit(X_train_m_enc, y_train_m_bin)\n",
        "\n",
        "y_pred_m_my_bin = my_log_reg.predict(X_test_m_enc)\n",
        "\n",
        "y_pred_m_my = np.where(y_pred_m_my_bin == 1, \"p\", \"e\")\n",
        "\n",
        "print(\"=== MyLogisticRegression (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_my))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_my))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_my))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208ca190",
      "metadata": {},
      "source": [
        "## 6. Анализ собственной реализации моделей\n",
        "\n",
        "### 6.1. Линейная регрессия (MyLinearRegression)\n",
        "\n",
        "Результаты собственной реализации:\n",
        "\n",
        "- **MAE ≈ 1810.56**\n",
        "- **RMSE ≈ 2237.28**\n",
        "- **R² ≈ 0.81710**\n",
        "\n",
        "Сравнение с базовой моделью `LinearRegression` из sklearn:\n",
        "\n",
        "| Модель                     | MAE      | RMSE     | R²       |\n",
        "|----------------------------|----------|----------|----------|\n",
        "| sklearn LinearRegression   | 1810.55  | 2237.29  | 0.81710  |\n",
        "| MyLinearRegression         | 1810.56  | 2237.28  | 0.81710  |\n",
        "\n",
        "Совпадение метрик подтверждает корректность реализации.  \n",
        "Использование нормального уравнения позволяет полностью повторить поведение базовой линейной регрессии без регуляризации.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.2. Логистическая регрессия (MyLogisticRegression)\n",
        "\n",
        "Результаты собственной реализации:\n",
        "\n",
        "- **Accuracy ≈ 0.99569**\n",
        "- Класс `e` классифицирован без ошибок.\n",
        "- Класс `p` имеет 7 ошибок вместо 1 в baseline sklearn-модели.\n",
        "- Матрица ошибок:\n",
        "[[842 0]\n",
        "[ 7 776]]\n",
        "\n",
        "\n",
        "Сравнение со sklearn LogisticRegression:\n",
        "\n",
        "| Модель                          | Accuracy |\n",
        "|----------------------------------|----------|\n",
        "| sklearn LogisticRegression       | 0.99938  |\n",
        "| MyLogisticRegression             | 0.99569  |\n",
        "\n",
        "Собственная реализация уступает sklearn из-за:\n",
        "- отсутствия регуляризации,\n",
        "- простого градиентного спуска,\n",
        "- фиксированного шага обучения,\n",
        "- меньшей точности оптимизации.\n",
        "\n",
        "Тем не менее модель обучается корректно и демонстрирует ожидаемое поведение логистической регрессии с вероятностным разделением классов.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.3. Итог по собственным моделям\n",
        "\n",
        "- Линейная регрессия полностью совпадает с результатами sklearn, подтверждая корректность алгоритма.\n",
        "- Логистическая регрессия показывает высокое качество, но проигрывает оптимизированной sklearn-реализации.\n",
        "- В обоих случаях собственные модели являются валидными и работают в соответствии с теоретическими ожиданиями.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59cff13",
      "metadata": {},
      "source": [
        "## 7. Итоговое сравнение моделей и выводы по лабораторной работе №2\n",
        "\n",
        "### 7.1. Классификация (Mushrooms)\n",
        "\n",
        "| Модель                                 | Accuracy |\n",
        "|----------------------------------------|----------|\n",
        "| Logistic Regression (baseline)         | 0.99938  |\n",
        "| Logistic Regression (improved, C=10)   | 1.00000  |\n",
        "| MyLogisticRegression                   | 0.99569  |\n",
        "\n",
        "Выводы:\n",
        "\n",
        "- Логистическая регрессия обучается практически идеально и достигает полной точности при подборе гиперпараметров.\n",
        "- Собственная реализация логистической регрессии уступает, но также показывает высокое качество.\n",
        "- Датасет остаётся полностью разделимым после One-Hot кодирования, что объясняет стабильность результатов.\n",
        "\n",
        "---\n",
        "\n",
        "### 7.2. Регрессия (Car Price Prediction)\n",
        "\n",
        "| Модель                       | MAE      | RMSE     | R²       |\n",
        "|-----------------------------|----------|----------|----------|\n",
        "| Linear Regression (baseline) | 1810.55  | 2237.29  | 0.81710  |\n",
        "| Ridge Regression (improved)   | 1807.84  | 2232.91  | 0.81781  |\n",
        "| MyLinearRegression            | 1810.56  | 2237.28  | 0.81710  |\n",
        "\n",
        "Выводы:\n",
        "\n",
        "- Линейная регрессия даёт высокое качество и превосходит KNN из ЛР1.\n",
        "- Регуляризация Ridge обеспечивает небольшое, но устойчивое улучшение метрик.\n",
        "- Собственная реализация линейной регрессии полностью совпадает со sklearn.\n",
        "\n",
        "---\n",
        "\n",
        "### 7.3. Общие выводы\n",
        "\n",
        "1. Линейные модели показали высокую эффективность как в классификации, так и в регрессии.\n",
        "2. Улучшение гиперпараметров влияет на качество, но в пределах ожидаемого: логистическая регрессия становится идеально точной, Ridge немного улучшает ошибки.\n",
        "3. Реализованные вручную модели подтверждают корректность математических основ алгоритмов.\n",
        "4. Лабораторная работа выполнена: создана база, улучшенные версии и собственные имплементации, проведено корректное сравнение.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

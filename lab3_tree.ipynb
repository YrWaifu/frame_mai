{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6bcbf289",
      "metadata": {},
      "source": [
        "# Лабораторная работа №3. Решающее дерево\n",
        "\n",
        "**Цель:** Исследование и реализация решающего дерева.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "94fa1b4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "mush = pd.read_csv(\"data/mushrooms.csv\")\n",
        "cars = pd.read_csv(\"data/car_price.csv\")\n",
        "\n",
        "X_mush = mush.drop(\"class\", axis=1)\n",
        "y_mush = mush[\"class\"]\n",
        "\n",
        "X_cars = cars.drop(\"Price\", axis=1)\n",
        "y_cars = cars[\"Price\"]\n",
        "\n",
        "# разбиение\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X_mush, y_mush, test_size=0.2, random_state=42, stratify=y_mush\n",
        ")\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X_cars, y_cars, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# препроцессоры\n",
        "preprocess_mush = ColumnTransformer(\n",
        "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), X_mush.columns.tolist())]\n",
        ")\n",
        "\n",
        "preprocess_cars = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), X_cars.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), X_cars.select_dtypes(include=[\"object\"]).columns.tolist())\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3291ea39",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Decision Tree Baseline (Mushrooms) ===\n",
            "Accuracy: 1.0\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  0 783]]\n"
          ]
        }
      ],
      "source": [
        "dt_clf_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_mush),\n",
        "    (\"model\", DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "dt_clf_baseline.fit(X_train_m, y_train_m)\n",
        "y_pred_m_dt = dt_clf_baseline.predict(X_test_m)\n",
        "\n",
        "print(\"=== Decision Tree Baseline (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_dt))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_dt))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_dt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "deb0cb17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Decision Tree Baseline (Cars) ===\n",
            "MAE: 2590.12241036684\n",
            "RMSE: 3192.0472249858512\n",
            "R^2: 0.6276799533493813\n"
          ]
        }
      ],
      "source": [
        "dt_reg_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_cars),\n",
        "    (\"model\", DecisionTreeRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "dt_reg_baseline.fit(X_train_c, y_train_c)\n",
        "y_pred_c_dt = dt_reg_baseline.predict(X_test_c)\n",
        "\n",
        "mae_dt = mean_absolute_error(y_test_c, y_pred_c_dt)\n",
        "rmse_dt = mean_squared_error(y_test_c, y_pred_c_dt)**0.5\n",
        "r2_dt = r2_score(y_test_c, y_pred_c_dt)\n",
        "\n",
        "print(\"=== Decision Tree Baseline (Cars) ===\")\n",
        "print(\"MAE:\", mae_dt)\n",
        "print(\"RMSE:\", rmse_dt)\n",
        "print(\"R^2:\", r2_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0f285c",
      "metadata": {},
      "source": [
        "## 2. Бейзлайн (Sklearn)\n",
        "\n",
        "1. **Mushrooms (Class):** Accuracy = 1.0. Идеально.\n",
        "2. **Cars (Reg):** MAE ~2590, R2 ~0.63.\n",
        "   Дерево без настройки переобучается и работает хуже линейной регрессии (R2 ~0.82).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5b6df133",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (DT Mushrooms): {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
            "\n",
            "=== Improved Decision Tree (Mushrooms) ===\n",
            "Accuracy: 1.0\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  0 783]]\n"
          ]
        }
      ],
      "source": [
        "# Улучшенное решающее дерево для грибов\n",
        "\n",
        "dt_clf_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_mush),\n",
        "    (\"model\", DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_clf = {\n",
        "    \"model__max_depth\": [None, 3, 5, 7, 10],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "    \"model__min_samples_leaf\": [1, 2, 5]\n",
        "}\n",
        "\n",
        "grid_dt_clf = GridSearchCV(\n",
        "    estimator=dt_clf_pipe,\n",
        "    param_grid=param_grid_clf,\n",
        "    cv=5,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_dt_clf.fit(X_train_m, y_train_m)\n",
        "\n",
        "print(\"Best params (DT Mushrooms):\", grid_dt_clf.best_params_)\n",
        "\n",
        "best_dt_clf = grid_dt_clf.best_estimator_\n",
        "\n",
        "y_pred_m_dt_best = best_dt_clf.predict(X_test_m)\n",
        "\n",
        "print(\"\\n=== Improved Decision Tree (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_dt_best))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_dt_best))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_dt_best))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "764e2ec8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (DT Cars): {'model__max_depth': 7, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2}\n",
            "\n",
            "=== Improved Decision Tree (Cars) ===\n",
            "MAE: 2090.5980932957514\n",
            "RMSE: 2633.0894896335567\n",
            "R^2: 0.74665692151086\n"
          ]
        }
      ],
      "source": [
        "# Улучшенное решающее дерево для машин\n",
        "\n",
        "dt_reg_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_cars),\n",
        "    (\"model\", DecisionTreeRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_reg = {\n",
        "    \"model__max_depth\": [None, 3, 5, 7, 10],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "    \"model__min_samples_leaf\": [1, 2, 5]\n",
        "}\n",
        "\n",
        "grid_dt_reg = GridSearchCV(\n",
        "    estimator=dt_reg_pipe,\n",
        "    param_grid=param_grid_reg,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_dt_reg.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(\"Best params (DT Cars):\", grid_dt_reg.best_params_)\n",
        "\n",
        "best_dt_reg = grid_dt_reg.best_estimator_\n",
        "\n",
        "y_pred_c_dt_best = best_dt_reg.predict(X_test_c)\n",
        "\n",
        "mae_dt_best = mean_absolute_error(y_test_c, y_pred_c_dt_best)\n",
        "rmse_dt_best = mean_squared_error(y_test_c, y_pred_c_dt_best)**0.5\n",
        "r2_dt_best = r2_score(y_test_c, y_pred_c_dt_best)\n",
        "\n",
        "print(\"\\n=== Improved Decision Tree (Cars) ===\")\n",
        "print(\"MAE:\", mae_dt_best)\n",
        "print(\"RMSE:\", rmse_dt_best)\n",
        "print(\"R^2:\", r2_dt_best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540fdc11",
      "metadata": {},
      "source": [
        "## 3. Улучшение (GridSearchCV)\n",
        "\n",
        "1. **Mushrooms**: Без изменений (1.0).\n",
        "2. **Cars**: Подбор глубины (`max_depth=7`) и размера листа улучшил R2 до ~0.75 (с 0.63). Переобучение уменьшилось.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "21060be9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded mushrooms: (6499, 117) (1625, 117)\n",
            "Encoded cars: (800, 18) (200, 18)\n"
          ]
        }
      ],
      "source": [
        "# Закодированные данные для своих реализаций\n",
        "\n",
        "X_train_m_enc = preprocess_mush.fit_transform(X_train_m)\n",
        "X_test_m_enc = preprocess_mush.transform(X_test_m)\n",
        "\n",
        "X_train_c_enc = preprocess_cars.fit_transform(X_train_c)\n",
        "X_test_c_enc = preprocess_cars.transform(X_test_c)\n",
        "\n",
        "print(\"Encoded mushrooms:\", X_train_m_enc.shape, X_test_m_enc.shape)\n",
        "print(\"Encoded cars:\", X_train_c_enc.shape, X_test_c_enc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "640ae616",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value  # значение в листе\n",
        "\n",
        "\n",
        "class MyDecisionTreeBase:\n",
        "    def __init__(self, max_depth=5, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.root = None\n",
        "\n",
        "    def _to_dense(self, X):\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        return np.array(X)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = self._to_dense(X)\n",
        "        y = np.array(y)\n",
        "        self.root = self._build_tree(X, y, depth=0)\n",
        "        return self\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        if (depth >= self.max_depth or\n",
        "            num_samples < self.min_samples_split or\n",
        "            len(np.unique(y)) == 1):\n",
        "            leaf_value = self._leaf_value(y)\n",
        "            return TreeNode(value=leaf_value)\n",
        "\n",
        "        best_feature, best_threshold = self._best_split(X, y)\n",
        "        if best_feature is None:\n",
        "            leaf_value = self._leaf_value(y)\n",
        "            return TreeNode(value=leaf_value)\n",
        "\n",
        "        left_mask = X[:, best_feature] <= best_threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
        "            leaf_value = self._leaf_value(y)\n",
        "            return TreeNode(value=leaf_value)\n",
        "\n",
        "        left_child = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_child = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        return TreeNode(feature_index=best_feature,\n",
        "                        threshold=best_threshold,\n",
        "                        left=left_child,\n",
        "                        right=right_child)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "        best_feature, best_threshold = None, None\n",
        "        best_score = np.inf\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            values = X[:, feature_idx]\n",
        "            unique_vals = np.unique(values)\n",
        "            if unique_vals.size == 1:\n",
        "                continue\n",
        "\n",
        "            thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2.0\n",
        "\n",
        "            for thr in thresholds:\n",
        "                left_mask = values <= thr\n",
        "                right_mask = ~left_mask\n",
        "                if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                score = self._split_criterion(y[left_mask], y[right_mask])\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_feature = feature_idx\n",
        "                    best_threshold = thr\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _leaf_value(self, y):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _split_criterion(self, y_left, y_right):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _predict_row(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature_index] <= node.threshold:\n",
        "            return self._predict_row(x, node.left)\n",
        "        else:\n",
        "            return self._predict_row(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = self._to_dense(X)\n",
        "        preds = [self._predict_row(row, self.root) for row in X]\n",
        "        return np.array(preds)\n",
        "\n",
        "\n",
        "class MyDecisionTreeClassifier(MyDecisionTreeBase):\n",
        "    def __init__(self, max_depth=5, min_samples_split=2, min_samples_leaf=1):\n",
        "        super().__init__(max_depth, min_samples_split, min_samples_leaf)\n",
        "\n",
        "    def _leaf_value(self, y):\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return values[np.argmax(counts)]\n",
        "\n",
        "    def _gini(self, y):\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        p = counts / counts.sum()\n",
        "        return 1.0 - np.sum(p ** 2)\n",
        "\n",
        "    def _split_criterion(self, y_left, y_right):\n",
        "        n = len(y_left) + len(y_right)\n",
        "        return (len(y_left) / n) * self._gini(y_left) + (len(y_right) / n) * self._gini(y_right)\n",
        "\n",
        "\n",
        "class MyDecisionTreeRegressor(MyDecisionTreeBase):\n",
        "    def __init__(self, max_depth=5, min_samples_split=2, min_samples_leaf=1):\n",
        "        super().__init__(max_depth, min_samples_split, min_samples_leaf)\n",
        "\n",
        "    def _leaf_value(self, y):\n",
        "        return np.mean(y)\n",
        "\n",
        "    def _mse(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0.0\n",
        "        return np.mean((y - np.mean(y)) ** 2)\n",
        "\n",
        "    def _split_criterion(self, y_left, y_right):\n",
        "        n = len(y_left) + len(y_right)\n",
        "        return (len(y_left) / n) * self._mse(y_left) + (len(y_right) / n) * self._mse(y_right)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7e77c48e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MyDecisionTreeClassifier (Mushrooms) ===\n",
            "Accuracy: 0.9987692307692307\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  2 781]]\n"
          ]
        }
      ],
      "source": [
        "my_dt_clf = MyDecisionTreeClassifier(max_depth=5, min_samples_split=5, min_samples_leaf=2)\n",
        "my_dt_clf.fit(X_train_m_enc, y_train_m)\n",
        "\n",
        "y_pred_m_my_dt = my_dt_clf.predict(X_test_m_enc)\n",
        "\n",
        "print(\"=== MyDecisionTreeClassifier (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_my_dt))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_my_dt))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_my_dt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3106b4b4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MyDecisionTreeRegressor (Cars) ===\n",
            "MAE: 2133.7195274674536\n",
            "RMSE: 2730.337840199153\n",
            "R^2: 0.727597818860648\n"
          ]
        }
      ],
      "source": [
        "my_dt_reg = MyDecisionTreeRegressor(max_depth=5, min_samples_split=5, min_samples_leaf=5)\n",
        "my_dt_reg.fit(X_train_c_enc, y_train_c)\n",
        "\n",
        "y_pred_c_my_dt = my_dt_reg.predict(X_test_c_enc)\n",
        "\n",
        "mae_my_dt = mean_absolute_error(y_test_c, y_pred_c_my_dt)\n",
        "rmse_my_dt = mean_squared_error(y_test_c, y_pred_c_my_dt)**0.5\n",
        "r2_my_dt = r2_score(y_test_c, y_pred_c_my_dt)\n",
        "\n",
        "print(\"=== MyDecisionTreeRegressor (Cars) ===\")\n",
        "print(\"MAE:\", mae_my_dt)\n",
        "print(\"RMSE:\", rmse_my_dt)\n",
        "print(\"R^2:\", r2_my_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7cbef13",
      "metadata": {},
      "source": [
        "## 4. Собственная реализация\n",
        "\n",
        "1. **MyDecisionTreeClassifier**: Accuracy ~0.999. Работает корректно.\n",
        "2. **MyDecisionTreeRegressor**: R2 ~0.73. Почти догнала улучшенный sklearn (0.75) и обогнала бейзлайн (0.63).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14b69081",
      "metadata": {},
      "source": [
        "## 5. Выводы\n",
        "\n",
        "| Модель | Задача | R2 / Accuracy |\n",
        "|---|---|---|\n",
        "| Tree Baseline | Reg | 0.628 |\n",
        "| Tree Improved | Reg | 0.747 |\n",
        "| My Tree | Reg | 0.728 |\n",
        "| Tree (Any) | Class | ~1.0 |\n",
        "\n",
        "Дерево требует настройки глубины для задач регрессии, иначе переобучается. Для простых задач классификации работает идеально \"из коробки\".\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c52fc4a",
      "metadata": {},
      "source": [
        "# Лабораторная работа №4. Случайный лес\n",
        "\n",
        "**Цель:** Исследование ансамблевого метода Random Forest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "138463ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "# загрузка\n",
        "mush = pd.read_csv(\"data/mushrooms.csv\")\n",
        "cars = pd.read_csv(\"data/car_price.csv\")\n",
        "\n",
        "# разбиение\n",
        "X_mush = mush.drop(\"class\", axis=1)\n",
        "y_mush = mush[\"class\"]\n",
        "\n",
        "X_cars = cars.drop(\"Price\", axis=1)\n",
        "y_cars = cars[\"Price\"]\n",
        "\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X_mush, y_mush, test_size=0.2, random_state=42, stratify=y_mush\n",
        ")\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X_cars, y_cars, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "preprocess_mush = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), X_mush.columns)\n",
        "])\n",
        "\n",
        "preprocess_cars = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), X_cars.select_dtypes(include=[\"int64\",\"float64\"]).columns),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), X_cars.select_dtypes(include=[\"object\"]).columns)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cc0d25ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Random Forest Baseline (Mushrooms) ===\n",
            "Accuracy: 1.0\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  0 783]]\n"
          ]
        }
      ],
      "source": [
        "rf_clf_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_mush),\n",
        "    (\"model\", RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "rf_clf_baseline.fit(X_train_m, y_train_m)\n",
        "y_pred_m_rf = rf_clf_baseline.predict(X_test_m)\n",
        "\n",
        "print(\"=== Random Forest Baseline (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_rf))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_rf))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_rf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "608ae751",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Random Forest Baseline (Cars) ===\n",
            "MAE: 1938.0169361012188\n",
            "RMSE: 2390.7719279368157\n",
            "R^2: 0.7911405644129668\n"
          ]
        }
      ],
      "source": [
        "rf_reg_baseline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_cars),\n",
        "    (\"model\", RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "rf_reg_baseline.fit(X_train_c, y_train_c)\n",
        "y_pred_c_rf = rf_reg_baseline.predict(X_test_c)\n",
        "\n",
        "mae_rf = mean_absolute_error(y_test_c, y_pred_c_rf)\n",
        "rmse_rf = mean_squared_error(y_test_c, y_pred_c_rf)**0.5\n",
        "r2_rf = r2_score(y_test_c, y_pred_c_rf)\n",
        "\n",
        "print(\"=== Random Forest Baseline (Cars) ===\")\n",
        "print(\"MAE:\", mae_rf)\n",
        "print(\"RMSE:\", rmse_rf)\n",
        "print(\"R^2:\", r2_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f51eb66",
      "metadata": {},
      "source": [
        "## 2. Бейзлайн (Sklearn)\n",
        "\n",
        "1. **Mushrooms**: Accuracy = 1.0.\n",
        "2. **Cars**: MAE ~1938, R2 ~0.79.\n",
        "   Случайный лес \"из коробки\" работает лучше решающего дерева (R2 0.63 -> 0.79), но пока уступает линейной регрессии (0.817).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fcb8214c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (RF Mushrooms): {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
            "\n",
            "=== Improved Random Forest (Mushrooms) ===\n",
            "Accuracy: 1.0\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00       842\n",
            "           p       1.00      1.00      1.00       783\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[842   0]\n",
            " [  0 783]]\n"
          ]
        }
      ],
      "source": [
        "rf_clf_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_mush),\n",
        "    (\"model\", RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_clf = {\n",
        "    \"model__n_estimators\": [100, 200],\n",
        "    \"model__max_depth\": [None, 5, 10],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "    \"model__min_samples_leaf\": [1, 2, 5]\n",
        "}\n",
        "\n",
        "grid_rf_clf = GridSearchCV(\n",
        "    rf_clf_pipe,\n",
        "    param_grid_clf,\n",
        "    cv=5,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf_clf.fit(X_train_m, y_train_m)\n",
        "\n",
        "print(\"Best params (RF Mushrooms):\", grid_rf_clf.best_params_)\n",
        "\n",
        "best_rf_clf = grid_rf_clf.best_estimator_\n",
        "y_pred_m_rf_best = best_rf_clf.predict(X_test_m)\n",
        "\n",
        "print(\"\\n=== Improved Random Forest (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_rf_best))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test_m, y_pred_m_rf_best))\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(confusion_matrix(y_test_m, y_pred_m_rf_best))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "90d05766",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params (RF Cars): {'model__max_depth': 10, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
            "\n",
            "=== Improved Random Forest (Cars) ===\n",
            "MAE: 1870.7702682059921\n",
            "RMSE: 2309.763864800643\n",
            "R^2: 0.8050546098436948\n"
          ]
        }
      ],
      "source": [
        "rf_reg_pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess_cars),\n",
        "    (\"model\", RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_reg = {\n",
        "    \"model__n_estimators\": [100, 200],\n",
        "    \"model__max_depth\": [None, 10, 20],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "    \"model__min_samples_leaf\": [1, 2, 5]\n",
        "}\n",
        "\n",
        "grid_rf_reg = GridSearchCV(\n",
        "    rf_reg_pipe,\n",
        "    param_grid_reg,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_rf_reg.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(\"Best params (RF Cars):\", grid_rf_reg.best_params_)\n",
        "\n",
        "best_rf_reg = grid_rf_reg.best_estimator_\n",
        "y_pred_c_rf_best = best_rf_reg.predict(X_test_c)\n",
        "\n",
        "mae_rf_best = mean_absolute_error(y_test_c, y_pred_c_rf_best)\n",
        "rmse_rf_best = mean_squared_error(y_test_c, y_pred_c_rf_best)**0.5\n",
        "r2_rf_best = r2_score(y_test_c, y_pred_c_rf_best)\n",
        "\n",
        "print(\"\\n=== Improved Random Forest (Cars) ===\")\n",
        "print(\"MAE:\", mae_rf_best)\n",
        "print(\"RMSE:\", rmse_rf_best)\n",
        "print(\"R^2:\", r2_rf_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08f88b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from scipy.stats import mode\n",
        "\n",
        "class MyRandomForestClassifier:\n",
        "    def __init__(self, n_estimators=10, max_depth=None, max_features='sqrt', random_state=42):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        # Convert to dense if sparse\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "            \n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        n_samples = X.shape[0]\n",
        "        \n",
        "        for i in range(self.n_estimators):\n",
        "            # Bootstrap\n",
        "            indices = rng.choice(n_samples, size=n_samples, replace=True)\n",
        "            X_sample, y_sample = X[indices], y[indices]\n",
        "            \n",
        "            tree = DecisionTreeClassifier(\n",
        "                max_depth=self.max_depth, \n",
        "                max_features=self.max_features, \n",
        "                random_state=rng.integers(10000)\n",
        "            )\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees]).T\n",
        "        # Majority vote\n",
        "        return mode(predictions, axis=1)[0].ravel()\n",
        "\n",
        "class MyRandomForestRegressor:\n",
        "    def __init__(self, n_estimators=10, max_depth=None, max_features='sqrt', random_state=42):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "            \n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        n_samples = X.shape[0]\n",
        "        \n",
        "        for i in range(self.n_estimators):\n",
        "            indices = rng.choice(n_samples, size=n_samples, replace=True)\n",
        "            X_sample, y_sample = X[indices], y[indices]\n",
        "            \n",
        "            tree = DecisionTreeRegressor(\n",
        "                max_depth=self.max_depth, \n",
        "                max_features=self.max_features, \n",
        "                random_state=rng.integers(10000)\n",
        "            )\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if hasattr(X, \"toarray\"):\n",
        "            X = X.toarray()\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees]).T\n",
        "        return predictions.mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "602fab2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Кодирование\n",
        "X_train_m_enc = preprocess_mush.fit_transform(X_train_m)\n",
        "X_test_m_enc = preprocess_mush.transform(X_test_m)\n",
        "X_train_c_enc = preprocess_cars.fit_transform(X_train_c)\n",
        "X_test_c_enc = preprocess_cars.transform(X_test_c)\n",
        "\n",
        "# My RandomForest Classification\n",
        "my_rf_clf = MyRandomForestClassifier(n_estimators=50, max_depth=None, random_state=42)\n",
        "my_rf_clf.fit(X_train_m_enc, y_train_m)\n",
        "y_pred_m_my = my_rf_clf.predict(X_test_m_enc)\n",
        "\n",
        "print(\"=== MyRandomForest (Mushrooms) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m_my))\n",
        "\n",
        "# My RandomForest Regression\n",
        "my_rf_reg = MyRandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
        "my_rf_reg.fit(X_train_c_enc, y_train_c)\n",
        "y_pred_c_my = my_rf_reg.predict(X_test_c_enc)\n",
        "\n",
        "print(\"\\n=== MyRandomForest (Cars) ===\")\n",
        "print(\"R2:\", r2_score(y_test_c, y_pred_c_my))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b40ce3d8",
      "metadata": {},
      "source": [
        "## 5. Выводы\n",
        "\n",
        "| Модель | Задача | R2 / Accuracy |\n",
        "|---|---|---|\n",
        "| RF Baseline | Reg | 0.791 |\n",
        "| RF Improved | Reg | 0.805 |\n",
        "| My RF | Reg | ~0.80 |\n",
        "\n",
        "Случайный лес показывает стабильно высокие результаты, превосходя одиночное решающее дерево. Собственная реализация на основе бутстрэпа работает корректно и показывает схожее качество."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ad0e41",
      "metadata": {},
      "source": [
        "## 4. Анализ улучшенного случайного леса\n",
        "\n",
        "### 4.1. Классификация (Mushrooms) — RandomForestClassifier\n",
        "\n",
        "Лучшие параметры по GridSearchCV:\n",
        "\n",
        "- **n_estimators = 100**\n",
        "- **max_depth = None**\n",
        "- **min_samples_split = 2**\n",
        "- **min_samples_leaf = 1**\n",
        "\n",
        "То есть оптимальная модель оказалась фактически полностью разветвлённым лесом без ограничений.\n",
        "\n",
        "Результаты:\n",
        "\n",
        "- **Accuracy = 1.0**\n",
        "- F1-score = 1.0\n",
        "- Матрица ошибок без ошибок\n",
        "\n",
        "Итог: улучшенный лес показывает те же результаты, что и baseline. Это ожидаемо: датасет полностью разделим, и любые адекватные модели достигают максимального качества.\n",
        "\n",
        "**Вывод:** улучшение гиперпараметров не меняет качество на этом датасете, но подтверждает устойчивость модели.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.2. Регрессия (Car Price Prediction) — RandomForestRegressor\n",
        "\n",
        "Лучшие параметры:\n",
        "\n",
        "- **n_estimators = 200**\n",
        "- **max_depth = 10**\n",
        "- **min_samples_split = 2**\n",
        "- **min_samples_leaf = 5**\n",
        "\n",
        "Результаты:\n",
        "\n",
        "- **MAE ≈ 1870.77**\n",
        "- **RMSE ≈ 2309.76**\n",
        "- **R² ≈ 0.80505**\n",
        "\n",
        "Сравнение baseline → improved:\n",
        "\n",
        "| Модель                        | MAE     | RMSE    | R²      |\n",
        "|-------------------------------|---------|---------|---------|\n",
        "| Random Forest (baseline)      | 1938    | 2391    | 0.791   |\n",
        "| **Random Forest (improved)**  | **1871**| **2310**| **0.805**|\n",
        "\n",
        "Улучшения заметные и стабильные:\n",
        "\n",
        "- уменьшение MAE и R\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
